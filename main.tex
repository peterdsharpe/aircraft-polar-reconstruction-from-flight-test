%! suppress = TooLargeSection
\documentclass[conf]{new-aiaa}
%\documentclass[journal]{new-aiaa} for journal papers

\input{preamble}

\title{Physics-Informed Regression and Uncertainty Quantification of Aircraft Performance from Minimal Flight Data}

\author{Peter Sharpe\footnote{PhD Candidate, AIAA Student Member} and R. John Hansman\footnote{T. Wilson Professor in Aeronautics, AIAA Fellow}}
\affil{Massachusetts Institute of Technology, Cambridge, MA}

\begin{document}

    \bibliographystyle{plain}

    \maketitle

    \begin{abstract}

        This work presents a rigorous statistical method for estimating an aircraft's aerodynamic and propulsive performance characteristics from minimal flight data. The method is based on a physics-informed regression approach, which uses a physics-based model of the aircraft's dynamics to constrain the regression problem. The method is demonstrated on a flight test dataset collected from a small electric aircraft. The results show that the method is able to estimate the aircraft's aerodynamic and propulsive performance characteristics with reasonable accuracy, and that the method is able to estimate the uncertainty in these estimates. The method is also shown to be robust to sensor noise and to missing data. Finally, the method is shown to be able to estimate the aircraft's performance characteristics from a single flight, which is a significant improvement over traditional methods.

    \end{abstract}

%    \section{Nomenclature}
%
%    {\renewcommand\arraystretch{1.0}
%    \noindent\begin{longtable*}{@{}l @{\quad=\quad} l@{}}
%                 $A$  & amplitude of oscillation \\
%                 $a$ &    cylinder diameter \\
%                 $C_p$& pressure coefficient \\
%                 $Cx$ & force coefficient in the \textit{x} direction \\
%                 $Cy$ & force coefficient in the \textit{y} direction \\
%                 c   & chord \\
%                 d$t$ & time step \\
%                 $Fx$ & $X$ component of the resultant pressure force acting on the vehicle \\
%                 $Fy$ & $Y$ component of the resultant pressure force acting on the vehicle \\
%                 $f, g$   & generic functions \\
%                 $h$  & height \\
%                 $i$  & time index during navigation \\
%                 $j$  & waypoint index \\
%                 $K$  & trailing-edge (TE) nondimensional angular deflection rate
%    \end{longtable*}}


    \section{Introduction}

    A primary goal of an initial flight test campaign of a new aircraft is to experimentally determine the aircraft's aerodynamic and propulsive performance characteristics. The desired outputs of this process typically include:

    \begin{enumerate}
        \item The aircraft's power curve, which gives the required power to maintain level flight as a function of airspeed.
        \item The aircraft's aerodynamic polar, which gives the relationship between the aircraft's lift and drag coefficients.
        \item The aircraft's propulsive efficiency curve, which yields the overall propulsive efficiency, typically as a function of throttle setting and/or propeller advance ratio, if relevant.
    \end{enumerate}

    All three of these results represent sweeps through the aircraft's flight envelope, varying the aircraft's airspeed, pitch trim setting, and throttle setting, and measuring the resulting lift, drag, and power required.

    \subsection{Traditional Flight Measurement Methods and Limitations}

    Typically, these performance outputs are obtained by performing an extensive campaign of careful, controlled flight experiments at quasi-steady flight conditions.

    For example, the aerodynamic polar is commonly measured by performing a series of long, steady power-off glides at different airspeeds. An implicit assumption here is that pitch trim is adjusted to maintain these airspeeds. Windmilling drag can also be estimated and calibrated out for improved accuracy, although this introduces additional uncertainty. The glide ratio (or equivalently, $L/D$) is then measured at a given airspeed by using a simple two-point finite-difference between the beginning and end of the glide:

    $$(L/D) = \frac{h(t_1) - h(t_2)}{V \cdot (t_2 - t_1)}$$

    where $h(t)$ represents the altitude at time $t$, and $V$ represents the airspeed. The drag is then computed as $D = W / (L/D)$, and $C_L$ and $C_D$ can be nondimensionalized from here.

    Similarly, the power curve is often measured by flying in steady level flight for an extended period at a given airspeed, adjusting pitch trim as needed. The input power to the propulsion system $P_{\rm in}$ is measured at a given throttle setting. In a liquid-fueled airplane, this can be computed using the fuel flow rate at a given throttle setting (read off the panel via a fuel flow meter) and the specific energy of the fuel. For an electric airplane, it can be computed as the product of battery current and voltage. This procedure is then repeated for a variety of airspeeds, and the resulting power curve is plotted.

    The propulsive efficiency can be roughly estimated based on these experiments as well. One possible procedure is as follows:

    \begin{enumerate}
        \item The input power to the propulsion system $P_{\rm in}$ is measured, as above.
        \item We observe the steady-state climb/sink rate of the aircraft at this throttle setting and we compare this to the power-off sink rate. The difference between these two sink rates represents the air power done by the propulsion system. The air power can be computed as:

        $$P_{\rm air}=T \cdot V = m g \left( \frac{dh}{dt}\Big |_\text{power on} - \frac{dh}{dt}\Big |_\text{power off} \right)$$

        \item Then, we can compute the propulsive efficiency as the ratio of the input power to the air power:

        $$\eta_{\rm propulsive} = \frac{P_{\rm air}}{P_{\rm in}}$$

    \end{enumerate}

    Traditional methods for measuring aerodynamic and propulsive performance have several limitations. The biggest limitation by far is that they require vast amounts of flight time to obtain a sufficient number of data points to characterize the aircraft's performance. This is both expensive and time-consuming.

    Furthermore, the aircraft must be flown at precisely-controlled conditions. This can be frustrating and tedious for the pilot, and it can also be dangerous if the aircraft is flown for an extended duration at conditions that are close to the edge of the flight envelope (e.g., behind the power curve on a not-yet-characterized experimental airplane).

    Traditional methods also make no direct estimate of sensor noise (and hence, uncertainty)â€”data is collected and averaged until the experimenter is satisfied that the data is ``good enough''. This is a subjective process, and it is difficult to quantify the uncertainty in the resulting performance estimates.

    Finally, traditional methods are not well-suited to estimating the performance of an aircraft that is not in steady flight. For example, data recorded during an aircraft's climb or descent to flight test altitude is typically discarded, which is wasteful; ideally, every single second of data should contribute to refining our estimate of the aircraft's performance.

    \subsection{Inference-Based Flight Data Reconstruction Methods}

    By contrast, we propose a method of estimating these performance characteristics which relies on a different perspective about flight testing. Traditionally, flight testing is viewed as a process of pure measurement, based only on analyzing the data itself. Instead, we view the aircraft flight test as a data-generating process, from which we can infer performance relationships. This might sound like a small difference, but it allows us to recognize that we actually have vastly more information about the aircraft than just the data itself, which in turn allows us to perform much more accurate performance reconstruction with a limited amount of data:

    Firstly, with certain reasonable assumptions about the sensor noise characteristics, the data itself can reveal a surprisingly large amount of information about the sensor noise. Essentially, this involves using the data to estimate the ``trustworthiness'' \emph{of the data itself}, a process described more fully in Section \ref{subsec:optimal_sensor_data_reconstruction}. One contribution of this work is a new cross-validation-like approach for estimating the sensor noise using only the properties of the data itself. This allows cleaner raw data inputs to the subsequent performance analysis toolchain that we develop, ultimately resulting in more accurate performance estimates and enabling uncertainty quantification.

    We also know certain characteristics of the aircraft's state based on physics, which can further increase the effective information density and significantly improve state estimation. For example, we know that the true state of the aircraft must follow invariants from Newtonian physics (e.g., conservation of energy). Embedding these invariants from physics reduces the number of unknowns, enabling more robust correction for unsteady effects. This is described in Section \ref{sec:physics_based_corrections}.

    Finally, there are characteristics about performance relations that we can be embedded from domain-specific expertise. Even for models that do not have simple, closed-form invariants, we almost always have some priors (i.e., informed guesses) about how performance parameters should be related - model structure. For example, we know that the aircraft's drag coefficient will primarily be a function of lift coefficient, and the general shape of this function is known. Similarly, we know that the propulsive efficiency will largely be a function of advance ratio, and the advance ratio can be inferred from the airspeed, input power, and first-order physics. Incorporation of these physics-based performance models embeds our physical understanding of the aircraft system into the estimation process, improving accuracy. For this reason, we term the performance reconstruction methodology described in this work a ``physics-informed'' approach.

    Figure \ref{fig:overall_procedure} broadly illustrates the toolchain for performance reconstruction that represents this work's central contribution.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics[width=\textwidth, trim=1cm 1cm 1cm 1cm,clip=true]{figures/overall_procedure}}
        \caption{Process for inference-based performance reconstruction from flight data}
        \label{fig:overall_procedure}
    \end{figure}


    \section{A Minimal Flight Test Dataset}

    To illustrate our proposed flight test data analysis procedure, this manuscript will use example data from a flight test conducted during MIT 16.821: Flight Vehicle Development, a senior-level aircraft design/build/fly capstone course at MIT AeroAstro. The flown aircraft, named \emph{Solar Surfer}, is a remote-controlled solar-electric seaplane design with a 14-foot wingspan. The as-flown all-up mass is 9.4 kg.

    General specifications of the aircraft can be found in the early design drawing that is reproduced in Appendix \ref{subsec:solar_surfer_drawing}. While this drawing does not reflect as-built weights or various planform adjustments that were made during preliminary design and construction, the overall configuration and performance numbers are representative of the aircraft that was flown.

    \subsection{Flight Test Campaign}

    The aircraft was flown in the vicinity of the Charles river basin near Cambridge, MA. Five tests were conducted on the morning of May 3, 2023, of which two were airborne flight tests. The final airborne flight test lasted approximately 260 seconds (4.3 minutes), beginning and ending with a successful water takeoff and landing. Figure \ref{fig:solar_surfer_flight} depicts a still image of the aircraft in flight. A simple racetrack-like pattern was flown, as shown in Figure \ref{fig:solar_surfer_track}. Winds were calm at roughly 1.5 m/s from the south.

    \begin{figure}[!htb]
        \centering
        \begin{subfigure}[b]{0.45\textwidth}
            \ifdraft{}{\includegraphics[width=\textwidth]{assets/Flight1_02549.JPG}}
            \caption{\emph{Solar Surfer} in flight}
            \label{fig:solar_surfer_flight}
        \end{subfigure}
        \hfill
        \begin{subfigure}[b]{0.511\textwidth}
            \ifdraft{}{\includegraphics[width=\textwidth]{assets/flight3-circuit}}
            \caption{Recorded GPS ground track during test flight}
            \label{fig:solar_surfer_track}
        \end{subfigure}
        \caption{\emph{Solar Surfer} aircraft test flight}
        \label{fig:solar_surfer_aircraft}
    \end{figure}

    Figure \ref{fig:raw_flight_data} illustrates the subset of the raw sensor data during flight that will be used for performance reconstruction. Overall, the data is reasonable, and we can clearly identify takeoff and landing by the strong increase in barometric altimeter noise near $t=0\ \rm sec$ and $t=263\ \rm sec$. We can also identify several distinct flight phases, such as a high-speed pass near $t=150\ \rm sec$ and gliding periods near $t=40\ \rm sec$, $t=210\ \rm sec$, and $t=250\ \rm sec$.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics[width=\textwidth]{figures/flight_raw_data}}
        \caption{Raw sensor data from test flight}
        \label{fig:raw_flight_data}
    \end{figure}


    However, there are two primary problems with the data we have. Firstly, all the data sources, and in particular the airspeed sensor, yield noisy measurements. The unsteady corrections that we will later implement require taking the derivative of this data; this is a problem because taking the derivative of noisy data tends to amplify the noise further.

    Secondly, the total amount of data is extremely limited, both in duration and sample rate. For example, there are only ~1,200 data points \emph{in total} for each of the plotted sensor traces, and this is before eliminating noise. After eliminating noise (which effectively acts as a low-pass filter on our data, as noise tends to be relatively high-frequency), the effective amount of information we have from the sensors is extremely low. While 1,200 data points might be sufficient to characterize the aircraft flight performance at a single operating point (i.e., a single power setting and airspeed), it is typically a vastly insufficient quantity of data to characterize any substantial portion of the flight envelope.

    Consider that even the most sophisticated techniques for system identification via statistical inference require the system to be observable in some form - no amount of math can recover a signal that is simply not present in the data. This is difficult, because after noise removal, the data really no more than perhaps a half-dozen ``system excitations'' from which we can infer aircraft performance. As a more intuitive analogy, consider that even the world's best test pilot can't accurately characterize the handling qualities of the aircraft without observing at least a few flight maneuvers.

    For these reasons, this dataset makes a good example case for what kinds of flight data reconstruction are possible with very limited, noisy data using statistical inference techniques and corrections from unsteady flight physics.

    \subsection{Naive Estimation of Power Curve}

    The most straightforward approach to estimating the aircraft's power curve is to simply cross-plot the airspeed and electrical power throughout the flight, and then to fit a curve to it.

    Figure \ref{fig:power_curve_naive} quickly illustrates the infeasibility of this approach. While a general trend is somewhat apparent (higher airspeeds yield higher power draw), the uncorrected data has far too much unexplained variation and noise to make any believable conclusions about the shape of the power curve.

    Figure \ref{fig:power_curve_naive} also demonstrates the pitfalls of naive curve-fitting in the absence of any kind of physics-based model structure. Perhaps the most severe of these is the extrapolation to physically-impossible conclusions. For example, the naive linear fit shown in blue would imply that the power draw at zero airspeed is negative, which is clearly impossible. The naive cubic fit shown in red initially appears more reasonable, although it too makes erroneous conclusions: it implies that beyond $20\ \rm m/s$, the power draw decreases with increasing airspeed. Clearly, our intuitions about what the ``correct'' model would look are not being incorporated into the curve-fitting process, and hence we are leaving information on the table.

    \begin{figure}[H]
        \centering
        \ifdraft{}{\includegraphics[width=\textwidth]{figures/power_polar_naive}}
        \caption{Raw uncorrected data for the power curve, with naive curve fitting. Uncorrected data exhibits high amounts of unexplained variance. Naive curve fits extrapolate to physically-impossible conclusions and do not capture uncertainty.}
        \label{fig:power_curve_naive}
    \end{figure}


    \section{Sensor Data Pre-Processing}

    The first contribution here is to develop a means of pre-processing the sensor data. Traditionally, noise is removed by simple averaging; after this process is complete, any uncertainty in the data is typically not considered, and the average is regarded as the ground truth. This works fine for traditional steady analysis where there is a wealth of data that we can average over.

    However, in cases where data is limited, we're strongly encouraged to find a way to extract some amount of information from unsteady data. This is difficult because it forces us to directly deal with the sensor noise (and embed priors about the bias-variance tradeoff of data), rather than hand-waving it away by averaging.

    As an illustrative example, imagine that we wish to reconstruct a \emph{truth} estimate of the airspeed from the example dataset. This truth value is not directly observable, although data from an associated airspeed sensor is. However, this sensor data has noise; hence, any attempt to reconstruct the truth value must adopt a strategy to separate the noise from the data.

    However, there are (literally) an infinite number of possible strategies that one can use to do this noise removal, depending on our embedded assumptions about how sensor noise is entering our data-generating process. For example, consider three different possible state estimations of the vehicle's airspeed, as illustrated in Figure \ref{fig:under_over_fitting}.

    \begin{figure}[H]
        \centering
        \ifdraft{}{\includegraphics[width=\textwidth]{figures/under_over_fitting}}
        \caption{Three possible curves that could be used to estimate the true underlying state of the vehicle. Airspeed data, zoomed to $t \in (60, 90)$; a subset of Figure \ref{fig:raw_flight_data}. 95\% confidence interval (CI) of reconstruction shaded in middle plot.}
        \label{fig:under_over_fitting}
    \end{figure}

    Ultimately, all three charts in Figure \ref{fig:under_over_fitting} represent different interpretations of the ground truth based on the data. If we didn't have any more information about the problem, all three could be equally justifiable given the appropriate contextâ€”but, in fact, we do have more information, since we know this data originates from a physical system.

    The chart on the left of Figure \ref{fig:under_over_fitting} is clearly overfitted (i.e., tracks the data too closely) based on engineering intuition. Essentially, we are assuming that each sample is the true data, and that each sample has no noise; hence, the ``truth'' curve exhibits extremely high variance (strong wiggles). There is no \emph{mathematical} reason why this interpretation can't be correct (it's theoretically possible that the sensor is giving perfect information), but of course, it is is \emph{physically} implausible for our system. If this interpretation were true, it would imply that the vehicle is achieving velocity-vector-aligned-accelerations on the order of 2.4 G, which is not physically plausible given the onboard propulsion system.

    The chart on the right of Figure \ref{fig:under_over_fitting} is clearly underfitted (i.e., tracks the data too slowly), as there are large regions where the estimator has a consistent bias (e.g., consistently too high or low) with respect to the underlying data. It might seem like there are no contexts where such an interpretation would be reasonable, but that is not necessarily the case. For example, if the sensor noise at each sample was not independent, but rather correlated with noise from the previous samples, we might not be able to rule out this interpretation of reality.

    Of course, a quick glance at the three charts above would tell us ``the middle one looks about right'', although it's not immediately clear why.

    \subsection{Optimal Sensor Data Reconstruction using Data-Driven Noise Estimates}
    \label{subsec:optimal_sensor_data_reconstruction}

    The key difference is that the middle chart embeds certain assumptions that we intuitively know about our data into its reconstruction. Specifically, the middle chart is an optimal reconstruction of the data assuming that:

    \begin{itemize}
        \item The noise in each sample is independent (i.e., uncorrelated with previous samples) and normally-distributed
        \item The noise is unbiased (i.e., there are no systematic errors in the data, only random ones)
        \item The noise is homoscedastic (i.e., the standard deviation of the noise is constant across the entire dataset)
        \item The sample rate is significantly higher than the underlying dynamics of the system that we're aiming to recover (i.e., the system is ``slow'' relative to the sample rate).
    \end{itemize}

    Under these assumptions above, the probabilistic properties of the noise reduce to a single parameter: the variance of the noise $\sigma^2_n$. Thus, by constructing an estimator for this statistic, we can recover the probability distribution of the noise and hence an optimal estimator of the data.

    \subsubsection{Motivation for Finding the Variance of the Noise}

    Because we're just one parameter away from having a probabilistic model of the sensor noise, we're strongly motivated to estimate this noise variance. Once we estimate the variance, we can begin to make optimal choices about the bias-variance tradeoff *with a rigorous definition of what optimal means* here.

    There is a second factor that motivates us to estimate the variance of the noise. Computing an optimal smoothing spline for a time-series dataset is a well-studied problem, but this process is greatly aided if we know the variance of the noise \cite{wahba}. So, if we can obtain an estimate of noise variance, we've done most of the work required to compute an optimal data reconstructor.

    In an ideal world, we would estimate this variance of the noise by taking a large number of samples while the vehicle is at some fixed, steady, known condition. For example, to estimate the airspeed data noise, we might place the aircraft in a wind tunnel at some constant speed. If we ran that experiment for an extended duration, we would know that the true underlying data was constant, and hence any observed variance in the samples would be due to the variance of the sensor noise.

    If we want to reconstruct data from unsteady measurement, however, we need to find a way to estimate the variance of the noise using the unsteady data itself, which is much more difficult.

    \subsubsection{Initial Approach and a First-Order Data-Based Noise Estimator}

    One way to do this is by assuming that the data is ``slow'' relative to the sample rate. If this is true, then subsequent samples will effectively have the same underlying truth value, but with noise drawn independently from the same underlying distribution.

    Quantitatively, if our true data is $x(t)$, and the noise of the sample $n(t)$ is drawn from $\mathcal{N}(0, \sigma^2_n)$, then our observed sensor data $s(t)$ will be:

    $$s(t_1) = x(t_1) + n(t_1)$$

    $$s(t_2) = x(t_2) + n(t_2)$$

    \noindent If $t_1 \approx t_2$ (as would be the case if we're looking at subsequent samples), then $x(t_1) \approx x(t_2)$, and hence:

    $$s(t_2) - s(t_1) \approx n(t_2) - n(t_1)$$

    In other words, the difference of two subsequent observed samples will be approximately equal to the difference of two independent draws from the same noise distribution. This means that we can estimate the variance of the noise by looking at the variance of the differences between subsequent samples.

    From the properties of the difference of two independent random normal variables, we can then say:

    $$n(t_2) - n(t_1) \sim \mathcal{N}(0, 2\sigma^2_n)$$

    \noindent where $\sigma^2$ is the variance of the sensor noise. So, the following is then approximately true:

    $$s(t_2) - s(t_1) \sim \mathcal{N}(0, 2\sigma^2_n)$$

    Therefore, by taking the mean difference across all adjacent pairs of sample data, we can reconstruct the variance of the noise as:

    \begin{equation}
        \sigma^2_n = \frac{1}{2 \cdot (N-1)} \sum_{i=1}^{N-1} \Big( s(t_{i+1}) - s(t_i) \Big)^2
        \label{eq:1st_order_noise_estimator}
    \end{equation}

    \noindent where $N$ is the number of samples in the dataset.

    \subsubsection{Numerical Demonstration of the First-Order Noise Estimator}

    We can demonstrate that this works in practice and is convergent to the correct answer by constructing a synthetic dataset with known noise properties, and then reconstructing the noise variance using the method above. The synthetic dataset we use is a simple sinusoid at some frequency $f_{\rm signal}$ with added independent, normally-distributed noise. We then sample this sinusoid at some frequency $f_{\rm sample}$ (ideally with $f_{\rm sample} \gg f_{\rm signal}$). We attempt to recover the noise variance using the method above and compare it to the true noise variance. This process is described in Figure \ref{fig:noise_variance_demo_procedure}, with results for the first-order estimator in the respective column of Table \ref{tab:noise_variance_demo}. The higher-order estimators are described in the following sections.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics[trim=1cm 1cm 1cm 1cm,clip=true]{figures/noise_variance_demo_procedure}}
        \caption{Procedure for numerical demonstration of estimator performance}
        \label{fig:noise_variance_demo_procedure}
    \end{figure}

    \begin{table}[!htb]
        \centering
        \caption{Numerical demonstration of noise variance estimator performance}
        \label{tab:noise_variance_demo}
        \begin{tabular}{@{}lll|lll@{}}
            \toprule
            & & & \multicolumn{3}{c}{Estimated $\sigma_n$} \\
            $f_{\rm signal}$ & $f_{\rm sample}$ & True $\sigma_n$ & 1st-order Estimator & 2nd-order Estimator & 4th-order Estimator \\ \midrule
            1                & 1000             & 0.1             & 0.0999              & 0.1006              & 0.1008              \\
            10               & 1000             & 0.1             & 0.1048              & 0.1006              & 0.1008              \\
            100              & 1000             & 0.1             & 0.3236              & 0.1491              & 0.1016              \\ \bottomrule
        \end{tabular}
    \end{table}

    As shown in Table \ref{tab:noise_variance_demo}, the first-order noise estimator yields a $\sigma_n$ value that is very close to the true value. We will also show later that this estimator is convergent to the true value as the number of samples increases.

    However, this estimator is only first-order convergent with respect to the ratio between the sampling frequency $f_{\rm sample}$ and the underlying dynamics of the system $f_{\rm signal}$. In other words, if the system is ``fast'' relative to the sample rate, then the estimator will be inaccurate. This is demonstrated in the third row of Table \ref{tab:noise_variance_demo}, where the estimator is off by a factor of 3. This is because the sinusoid is sampled at a frequency that is only 10 times higher than the frequency of the sinusoid itself. In this case, the estimator is not accurate, and we need to use a more sophisticated estimator.

    \subsubsection{Second-Order Noise Estimator}

    To do a better job of estimating the noise variance even in cases where $f_{\rm sample} \gg f_{\rm signal}$ doesn't strictly hold, we can use a second-order estimator. With this extension, we use a three-point numerical stencil.

    Derivation of this estimator follows similar principles to the first-order estimator above, with the key result as follows:

    \begin{equation}
        \sigma^2 = \frac{1}{6 \cdot (N-2)} \sum_{i=1}^{N-2} \Big( s(t_{i+2}) - 2 \cdot s(t_{i+1}) + s(t_i) \Big)^2
        \label{eq:2nd_order_noise_estimator}
    \end{equation}

    \noindent where $N$ is the number of samples in the dataset.

    As shown in Table \ref{tab:noise_variance_demo}, the second-order estimator has superior performance to the first-order estimator when the sample and signal frequencies are not well-separated.

    Notably, this effectively implements a first-order, second-degree finite-difference of the underlying dataâ€”a discrete derivative. It's instructive to consider the theoretical underpinning of using a discrete derivative operator here. If we assume that the underlying true signal is relatively low-frequency (i.e., smooth), then as we take more discrete derivatives of the observed data, the signal component will asymptote to zero (assuming $f_{\rm sample} \geq f_{\rm signal}$). Stated equivalently, the frequency spectrum of the true signal is assumed to have some cutoff frequency (analogous to $f_{\rm signal}$), above which the power spectral density gradually goes to zero. We don't need to specify this cutoff frequency or know it precisely \emph{a priori}; the remarks presented here merely require that one exists and is somewhere below $f_{\rm sample}$.

    In contrast, the noise is assumed to be independent, which means that the noise component of the observed data will not go to zero as we take successive derivatives. Stated equivalently, the frequency spectrum of the noise is white, with uniform spectral power across all frequencies. Therefore, repeated application of the discrete derivative operator acts as a way to spectrally-separate the noise from the signal. This is a key insight that we will use later in this work.

    \subsubsection{Arbitrary-Order Estimators}

    Clearly, the second-order estimator improves performance compared to the first-order one. Interestingly, we can generalize the logic to an $d$-th order estimator by observing that the denominator is the sum of the squares of the first-order, $d$-th-degree, uniform-grid finite difference coefficients (or, perhaps more intuitively, the elements of the $d$-th row of Pascal's triangle). Then, we use the combinatorial trick that:

    \begin{equation}
    {d \choose 0}
        ^2 + {d \choose 1}^2 + \dots + {d \choose d}^2 = {2 d \choose d} = \frac{(2d)!}{(d!)^2}
    \end{equation}

    to derive the following $d$-th order estimator of the noise variance:

    \begin{equation}
        \sigma^2 =
        \frac{1}{{2 d \choose d} \cdot (N-d)}
        \cdot \sum_{i=1}^{N-d} \left[
            {d \choose 0} s(t_i)
        - {d \choose 1} s(t_{i+1})
        + {d \choose 2} s(t_{i+2})
        - {d \choose 3} s(t_{i+3})
        \pm \dots
        \mp {d \choose d} s(t_{i+d})
        \right]^2
        \label{eq:arbitrary_order_noise_estimator}
    \end{equation}

    While we have shown that the second-order estimator has improved robustness to low sample rates, it is not immediately clear that this will hold for arbitrary orders - as the order increases, we might expect to see some form of numerical instability as we take successively higher-order derivatives of noisy data. To test this, we can plot the performance of noise estimators of various orders, as shown in Figure \ref{fig:noise_variance_higher_order}.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics{figures/noise_variance_higher_order}}
        \caption{Performance of higher-order data-driven noise estimators}
        \label{fig:noise_variance_higher_order}
    \end{figure}


    The figure above shows something quite remarkable: we can use extremely-high-order estimators (even up to the 512th order, i.e., taking the 512th-derivative of raw, noisy data via finite differences), and we see not only that it's numerically stable, but also that it accurately estimates the true noise variance even when the underlying signal is almost at the Nyquist frequency.

    Interestingly, except for a miniscule region near the Nyquist frequency, estimator performance seems to monotonically improve with increasing estimator order. Since practical data reconstruction would likely have the $f_{\rm sample} / f_{\rm signal}$ ratio be much larger than 2, this suggests that we can use extremely-high-order estimators to estimate the noise variance with very high accuracy.

    \subsection{Uncertainty Quantification Using Noise Variance Estimators}

    With the ability to estimate the amount of noise in the data, we can also estimate the uncertainty of our resulting models and curve fits. To do this, we combine a resampling bootstrap approach (described in \cite{surrogates, elements_of_statistical_learning}) with a noise-variance-aware spline interpolator (described in \cite{surrogates, wahba}). Together, these yield not only a best-estimate of the underlying model, but also a measure of the uncertainty in that estimate. An example is depicted in Figure \ref{fig:power_curve_spline_but_no_physics}, which uses the same power-curve dataset as in Figure \ref{fig:power_curve_naive}.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics[]{figures/power_polar_spline_but_no_physics}}
        \caption{Raw uncorrected data for the power curve, with noise-variance-aware spline interpolation. A resampling bootstrap allows uncertainty quantification.}
        \label{fig:power_curve_spline_but_no_physics}
    \end{figure}

    Figure \ref{fig:power_curve_spline_but_no_physics} certainly represents an improvement over the naive curve fits shown in Figure \ref{fig:power_curve_naive} in that it leverages uncertainty. For example, the uncertainty narrows near $19\ \rm m/s$ where data is abundant, and it widens considerably below $7\ \rm m/s$ where data is sparse. This awareness of model uncertainty reduces our propensity to make statistical conclusions that go beyond what the data can truly support.

    Furthermore, this uncertainty quantification allows us to determine where in the flight envelope more data should be collected (i.e., serve as an acquisition function). For example, to refine the power curve of Figure \ref{fig:power_curve_spline_but_no_physics}, we might aim to fly future test flights at speeds between 13 and 17 m/s.

    With this said, two major problems remain with the approach of Figure \ref{fig:power_curve_spline_but_no_physics}:

    \begin{enumerate}
        \item The resulting model uncertainty is extremely high, as shown by the shaded confidence intervals in Figure \ref{fig:power_curve_spline_but_no_physics}. For example, the tightest that we can bound the required power at $10\ \rm m/s$ with reasonably-strong confidence (95\% confidence interval) is between $30$ and $190$ Watts. This is a huge range and not a particularly useful insight. Near the low end of the airspeed range, the model uncertainty becomes so large that even the most basic claims are impossible to assert.
        \item The model still allows physically-implausible relationships, such as the unexplained power curve increase near $13\ \rm m/s$ and the flattening power curve near $20\ \rm m/s$. Clearly, the uncertainty bounds here are wider than what they would be if our physical insights were incorporated into the model.
    \end{enumerate}


    \section{Incorporating Physics-Based Data Corrections and Domain-Specific Knowledge}
    \label{sec:physics_based_corrections}

    When inferring the performance characteristics of a physical system, the laws governing that system can be used to significantly narrow the solution space and reduce the unexplainable variance in the data.

    \subsection{The Aircraft as an Energy System}

    In the example of the power curve regression, one way to do this is to consider the aircraft as an energy system and exploit the fact that energy should be conserved. Consider the following basic accounting equation for the total energy of an aircraft at some time $t$:

    \begin{equation}
        E_{\rm total}(t) =
        \frac{1}{2}m \, U(t)^2
        + m \, g \, h(t)
        + \int_0^t \left[ P_{\rm thrust}(\tau)
        - P_{\rm loss}(\tau)
        \right] \, d\tau
        \label{eq:total_energy}
    \end{equation}

    \begin{eqexpl}
        \item{$E_{\rm total}$} Total energy of the aircraft system. System boundary includes the aircraft but not the onboard stored energy (e.g., battery) or power-to-air (e.g., drag); hence, the representation of these as flow terms.
        \item{$m$} Mass of the aircraft
        \item{$U(t)$} Airspeed of the aircraft at time $t$
        \item{$g$} Local gravitational acceleration
        \item{$h(t)$} Altitude of the aircraft at time $t$
        \item{$P_{\rm thrust}(t)$} Thrust power ($\text{thrust} \cdot U$) to the aircraft at time $t$
        \item{$P_{\rm loss}(t)$} Power lost from the aircraft at time $t$; primarily drag, but also other system losses
    \end{eqexpl}

    \noindent We can differentiate this equation with respect to time to obtain an expression for the total power. As this is a system with all energy flows accounted for, the total power must equal zero for energy conservation to hold. In writing the following expression, we can also expand the power gains and losses into constituent terms as appropriate for an electric aircraft:

    \begin{equation}
        P_{\rm total}(t) =
        m \, U(t) \, \dot{U}(t)
        + m \, g \, \dot{h}(t)
        + \left[
        V(t) \, i(t) \, \eta_{\rm propulsive}(\theta)
        - P_{\rm avionics}
        - U(t) \, D(\theta)
        \right] = 0
        \label{eq:total_power}
    \end{equation}

    \begin{eqexpl}
        \item {$\dot{(\:)}$} Time derivative
        \item {$P_{\rm total}(t)$} Total power at time $t$
        \item {$V(t)$} Battery voltage at time $t$
        \item {$i(t)$} Battery current at time $t$
        \item {$\eta_{\rm propulsive}(\theta)$} Propulsive efficiency ($P_{\rm thrust} / P_{\rm in}$) as a function of both flight data and unknown parameters $\theta$
        \item {$P_{\rm avionics}$} Power consumed by avionics. In the case of the example dataset, this is assumed to be constant and equal to the average measured power consumption during motor-off periods.
        \item {$D(\theta)$} Drag as a function of both flight data and unknown parameters $\theta$
    \end{eqexpl}

    Ideally, this equation would be used to simply correct the data for the unsteady terms (i.e., acceleration and climb terms) in Equation \ref{eq:total_power}, at which point we would directly use that data and apply traditional curve-fitting techniques. However, the observant reader will notice that Equation \ref{eq:total_power} cannot, on its own, be used to correct the data. Both the propulsive efficiency and drag terms are unknown functions of the flight data and unknown parameters $\theta$, and hence these need to be solved for.

    These parameters can be defined as the solution of a residual minimization problem (i.e., optimization) between our data and modelâ€”effectively, system identification. However, the interesting insight here is that changes to our model parameters affect \textit{both} the model and the corrected data, and hence the model and data must be optimized simultaneously. Stated equivalently: we are not only correcting the data using our models; we are also simultaneously fitting the models to the data.

    One other consideration to note with this energy-corrected formulation is that it relies on the time derivative of sensor data. Because our data reconstructors from Section \ref{subsec:optimal_sensor_data_reconstruction} are based on splines, these can be conveniently differentiated by conducting simple polynomial differentiation piecewise between knot points. However, the derivative of the best estimator is not necessarily the bias-variance-optimal estimator of the derivative, due to the amplification of high-frequency variation during the differentiation process. To combat this, we add a Gaussian low-pass-filter with time constant $\sigma=4\ \rm sec$ to the derivative estimator; developing a rigorous method for determining the optimal filter time constant is left as future work.

    \subsection{Modeling the Unknown Functions}
    \label{subsec:modeling_unknown_functions}

    There are two unknown models in Equation \ref{eq:total_power}: the propulsive efficiency and the drag. Basic model forms for both unknown functions can be taken from domain-specific expertise.

    \subsubsection{Drag Model}
    \label{subsubsec:drag_model}
    The aerodynamic drag can be modeled as a function of airspeed. To do this, we use the following procedure:

    \begin{enumerate}
        \item Compute the instantaneous lift coefficient $C_L(t)$ from the airspeed $U(t)$, assuming a load factor of 1 and known aircraft properties.
        \item Map the $C_L$ to a drag coefficient $C_D$ using the following model form and unknown parameters $\theta$:

        \begin{equation*}
            C_D =
            \theta_0
            \: + \: \theta_2 \cdot (C_L - \theta_1)^2
            \: + \: \theta_3 \cdot |C_L - \theta_1|^3
            \: + \: \theta_4 \cdot (C_L - \theta_1)^4
            \label{eq:drag_coefficient}
        \end{equation*}
        \noindent where all parameters $\theta_i$ here are constrained to be nonnegative.
        \item Dimensionalize the computed $C_D$ to obtain the drag.
    \end{enumerate}

    \subsubsection{Propulsive Efficiency Model}
    \label{subsubsec:propulsive_efficiency_model}

    Similarly, a characteristic model for the propulsive efficiency can be computed as follows:

    \begin{enumerate}
        \item Use the measured current $i(t)$ to estimate $c_n$ a quantity proportional to the propeller rotational rate $n$, using the $P_{\rm in}\propto n^3$ relationship found using the Buckingham $\pi$ theorem \cite{unified_propellers}:
        \begin{equation*}
            c_n = i(t)^{1/3} \propto n
        \end{equation*}
        \item Propagate this to estimate $c_J$, a quantity proportional to the propeller advance ratio $J$:
        \begin{equation*}
            c_J = \frac{U(t)}{c_n} \propto J
        \end{equation*}
        \item Map $c_J$ to a propulsive efficiency $\eta_{\rm propulsive}$ using the following model form and unknown parameters $\theta$:

        \begin{equation*}
            \eta_{\rm propulsive} =
            \theta_5
            + \theta_6 \cdot \tanh \left(
            \frac{c_J}{\theta_7} - \theta_8
            \right)
        \end{equation*}

        \noindent where all parameters $\theta_i$ here are constrained in such a way that $0 \leq \eta_{\rm propulsive} \leq 1$ always.

    \end{enumerate}

    \subsection{Solving the Optimization Problem}
    \label{subsec:solving_optimization_problem}

    With these models in place, a residual minimization problem of the following form can be solved to yield optimal $\theta$ values, where $P_{\rm total}$ from Equation \ref{eq:total_power} is used as the residual:

    \begin{mini}
        |l|
            {\theta}{\sum (P_{\rm total})^2}
            {}{}
        \addConstraint{\theta\ \text{constraints described in Section \ref{subsec:modeling_unknown_functions}}}
        \label{eq:}
    \end{mini}

    Optionally, other norms of the $P_{\rm total}$ residual vector can be minimized instead. The $L_1$ norm makes a particularly compelling choice here due to its robustness to outliers \cite{brunton}. In the example problem here, we solve this optimization problem numerically using IPOPT \cite{ipopt} via the AeroSandbox \cite{aerosandbox} framework for engineering design optimization.

    \subsection{Results}

    With the optimization problem solved, we can now use the resulting $\theta$ values to compute the corrected data and model. This is shown in Figure \ref{fig:power_curve_with_physics}. The corrected data and model are now in excellent agreement, and the corrected data has significantly less unexplained variance than the raw data.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics[]{figures/power_curve_with_physics}}
        \caption{Power curve with physics-informed corrections on data and model, and using noise estimator with a resampling bootstrap for uncertainty quantification.}
        \label{fig:power_curve_with_physics}
    \end{figure}

    Conveniently, this process yields other critical performance information, like the aerodynamic polar and propulsive efficiency curve, ``for free'' as part of the fitting process. Furthermore, we also obtain uncertainty estimates for all these quantities, which are critical for understanding the confidence we can have in the results. An example of this is shown in \ref{fig:aerodynamic_polar_with_physics}.

    \begin{figure}[!htb]
        \centering
        \ifdraft{}{\includegraphics[]{figures/aerodynamic_polar_with_physics}}
        \caption{Aerodynamic polar with physics-informed corrections on data and model, and using noise estimator with a resampling bootstrap for uncertainty quantification.}
        \label{fig:aerodynamic_polar_with_physics}
    \end{figure}

    Compared to the naive approach in Figure \ref{fig:power_curve_naive}, Figure \ref{fig:power_curve_with_physics} enables us to make very accurate and physically-grounded assertions about the performance of the airplane, based on minimal data (here, only four minutes of flight time).


    \section{Reproducibility Statement}

    All code and data used in this paper is publicly available at \url{https://github.com/peterdsharpe/aircraft-polar-reconstruction-from-flight-test}.


    \section{Conclusion}

    In this paper, we have demonstrated a rigorous method for reconstructing the performance characteristics of an aircraft from flight test data. This method is based on a physics-informed correction of the data and model, and is shown to be effective at recovering the true power curve and aerodynamic polar of an example aircraft from noisy, limited, unsteady data. This method is also shown to be robust to the presence of outliers in the data, and to be able to provide uncertainty estimates for the resulting aerodynamic polar. This method is also shown to be able to recover the propulsive efficiency curve of the aircraft, which is a critical quantity for understanding the performance of the aircraft. Finally, this method is shown to be able to recover the aerodynamic polar of the aircraft from only four minutes of flight test data, which is a significant reduction in the amount of data required compared to the state of the art.

    A fair point of hesitancy here might be the fact that applying these corrections to recover useful insights from noisy, limited, unsteady data takes a significant amount of algorithmic development and mathematical complexity. However, algorithms are cheap, and more importantly, \emph{scalable} - so, once a computational workflow is established, it can easily be applied to a large number of flight test campaigns. By contrast, flight-test hours and improved instrumentation represent a recurring high cost. Therefore, it is worth investing in the development of algorithms that can extract the maximum amount of useful insight from the data that we do collect, even if this analysis is less simple.


    \section*{Appendix}

    \newpage

    \subsection{Solar Surfer Design Drawing}
    \label{subsec:solar_surfer_drawing}

    \begin{figure}[H]
        \centering
        \ifdraft{}{\includegraphics[width=\textwidth]{assets/seaway_mini_packet_Page_1}}
        \label{fig:solar_surfer_design}
    \end{figure}

    \newpage

    \subsection{Efficient Computational Implementation of Arbitrary-Order Noise Estimator}

    While the given equation for an arbitrary-order data-driven noise estimator (Equation \ref{eq:arbitrary_order_noise_estimator}) is mathematically correct, it is nontrivial to computationally implement. This is because an implementation as-written involves combinatorial coefficients that grow exponentially with the order of the estimator, quickly exceeding standard double-precision floating-point overflow. A naive implementation also has a runtime complexity that scales linearly with both with the number of samples in the dataset and the order of the estimator, making it computationally unattractive for large datasets or high-order estimators.

    An efficient computational implementation of the arbitrary-order noise estimator is given below. This example uses NumPy and SciPy within Python 3. This implementation uses the log-gamma function to both nullify the complexity scaling with respect to estimator order as well as prevent numerical overflow. The implementation also uses a convolutional kernel to vectorize the summation, enabling further speedups.

    \begin{listing}[H]
        \begin{minted}[mathescape=true]{python}
import numpy as np
from scipy.special import gammaln

def estimate_noise_standard_deviation(
        data: np.ndarray,
        estimator_order: int = 10,
) -> float:
    ### For speed, pre-compute the log-factorial of integers from 0 to estimator_order
    ln_factorial = lambda x: gammaln(x + 1)
    ln_f = ln_factorial(np.arange(estimator_order + 1))

    ### Create a convolutional kernel to vectorize the summation
    coefficients = np.exp(
        2 * ln_f[estimator_order] - ln_f - ln_f[::-1] - 0.5 * ln_factorial(2 * estimator_order)
    ) * (-1) ** np.arange(estimator_order + 1)
    coefficients -= np.mean(coefficients) # Remove any bias introduced by floating-point error

    sample_stdev = np.convolve(data, coefficients[::-1], 'valid')
    return np.mean(sample_stdev ** 2) ** 0.5

        \end{minted}
        \caption{Example efficient implementation of the arbitrary-order noise estimator using NumPy/SciPy in Python 3.}
        \label{listing:efficient_arbitrary_order_noise_estimator}
    \end{listing}

    \section*{Acknowledgments}
    The authors would like to thank the MIT AeroAstro 16.821 course staff for their support of this work, and the MIT AeroAstro department for their support of the course. The aircraft used to collect the example data in this work was constructed by the MIT AeroAstro 16.821 student team, and the authors would like to thank the team for their hard work and dedication to the project.

    \bibliography{main}

\end{document}
